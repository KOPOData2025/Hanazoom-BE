package com.hanazoom.domain.stock.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;

import java.util.Map;
import org.springframework.stereotype.Service;

import javax.annotation.PostConstruct;

import java.time.LocalDateTime;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

@Slf4j
@Service
@RequiredArgsConstructor
@ConditionalOnProperty(value = "kafka.enabled", havingValue = "true", matchIfMissing = false)
public class KafkaStockConsumer {

    @PostConstruct
    public void init() {
        log.info("ğŸ¯ Kafka Consumer ì´ˆê¸°í™” ì‹œì‘ - WebSocketê³¼ ì™„ì „íˆ ë¶„ë¦¬ë¨");

        new Thread(() -> {
            try {

                Thread.sleep(2000); 
                log.info("âœ… Kafka Consumer ì´ˆê¸°í™” ì™„ë£Œ - WebSocketê³¼ ë…ë¦½ì  ë™ì‘");
            } catch (Exception e) {
                log.warn("âš ï¸ Kafka ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ (WebSocketì—ëŠ” ì˜í–¥ ì—†ìŒ): {}", e.getMessage());
            }
        }).start();
    }

    private final ObjectMapper objectMapper;
    private final KafkaStockService kafkaStockService;


    private final Map<String, Map<String, Object>> realTimeStockCache = new ConcurrentHashMap<>();


    private final AtomicLong totalMessagesProcessed = new AtomicLong(0);
    private final AtomicLong totalProcessingTime = new AtomicLong(0);
    private final AtomicInteger activeConnections = new AtomicInteger(0);


    private static final String STOCK_REALTIME_TOPIC = "stock-realtime-data";
    private static final String PERFORMANCE_METRICS_TOPIC = "performance-metrics";

    @KafkaListener(topics = STOCK_REALTIME_TOPIC, groupId = "wts-consumer-group")
    public void consumeRealTimeStockData(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic,
            @Header("kafka_receivedPartitionId") String partition,
            @Header("kafka_receivedTimestamp") String timestamp
    ) {
        long startTime = System.currentTimeMillis();

        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String stockCode = jsonNode.get("stockCode").asText();
            String stockName = jsonNode.get("stockName").asText();
            String currentPrice = jsonNode.get("currentPrice").asText();
            String changePrice = jsonNode.get("changePrice").asText();
            String changeRate = jsonNode.get("changeRate").asText();
            String changeSign = jsonNode.get("changeSign").asText();


            Map<String, Object> stockData = Map.of(
                "stockCode", stockCode,
                "stockName", stockName,
                "currentPrice", currentPrice,
                "changePrice", changePrice,
                "changeRate", changeRate,
                "changeSign", changeSign,
                "timestamp", LocalDateTime.now()
            );

            realTimeStockCache.put(stockCode, stockData);


            long processingTime = System.currentTimeMillis() - startTime;
            totalMessagesProcessed.incrementAndGet();
            totalProcessingTime.addAndGet(processingTime);

            log.debug("ğŸ“ˆ Kafka ìˆ˜ì‹  - ì‹¤ì‹œê°„ ë°ì´í„°: {} - {} (ì²˜ë¦¬ì‹œê°„: {}ms)",
                     stockCode, currentPrice, processingTime);


            if (totalMessagesProcessed.get() % 10 == 0) {
                sendPerformanceMetrics();
            }

        } catch (Exception e) {
            log.error("âŒ Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    @KafkaListener(topics = "stock-batch-data", groupId = "wts-consumer-group")
    public void consumeBatchStockData(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic
    ) {
        long startTime = System.currentTimeMillis();

        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String batchId = jsonNode.get("batchId").asText();
            String type = jsonNode.get("type").asText();

            log.info("ğŸ“¦ Kafka ìˆ˜ì‹  - ë°°ì¹˜ ë°ì´í„°: {} (íƒ€ì…: {})", batchId, type);




            long processingTime = System.currentTimeMillis() - startTime;
            log.debug("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {} (ì²˜ë¦¬ì‹œê°„: {}ms)", batchId, processingTime);

        } catch (Exception e) {
            log.error("âŒ ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    @KafkaListener(topics = PERFORMANCE_METRICS_TOPIC, groupId = "wts-consumer-group")
    public void consumePerformanceMetrics(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic
    ) {
        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String metricType = jsonNode.get("metricType").asText();
            String service = jsonNode.get("service").asText();

            log.info("ğŸ“Š Kafka ìˆ˜ì‹  - ì„±ëŠ¥ ë©”íŠ¸ë¦­: {} from {}", metricType, service);

        } catch (Exception e) {
            log.error("âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    public Map<String, Object> getRealTimeStockData(String stockCode) {
        return realTimeStockCache.get(stockCode);
    }

    public Map<String, Map<String, Object>> getAllRealTimeStockData() {
        return new ConcurrentHashMap<>(realTimeStockCache);
    }

    public int getCachedStockCount() {
        return realTimeStockCache.size();
    }

    private void sendPerformanceMetrics() {
        try {
            long avgProcessingTime = totalMessagesProcessed.get() > 0
                ? totalProcessingTime.get() / totalMessagesProcessed.get()
                : 0;

            kafkaStockService.sendWTSPerformanceMetrics(
                activeConnections.get(),
                realTimeStockCache.size(),
                avgProcessingTime,
                0.0, 
                Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()
            );

        } catch (Exception e) {
            log.error("âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì „ì†¡ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    public void incrementActiveConnections() {
        activeConnections.incrementAndGet();
    }

    public void decrementActiveConnections() {
        activeConnections.decrementAndGet();
    }

    public Map<String, Object> getConsumerStatus() {
        long avgProcessingTime = totalMessagesProcessed.get() > 0
            ? totalProcessingTime.get() / totalMessagesProcessed.get()
            : 0;

        return Map.of(
            "totalMessagesProcessed", totalMessagesProcessed.get(),
            "avgProcessingTime", avgProcessingTime,
            "cachedStocks", realTimeStockCache.size(),
            "activeConnections", activeConnections.get(),
            "timestamp", LocalDateTime.now()
        );
    }
}
